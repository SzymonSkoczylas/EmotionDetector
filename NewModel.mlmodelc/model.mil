program(1.0)
[buildInfo = dict<tensor<string, []>, tensor<string, []>>({{"coremlc-component-MIL", "5.33.5"}, {"coremlc-version", "1877.40.3"}, {"coremltools-component-tensorflow", "2.12.1"}, {"coremltools-version", "7.2"}})]
{
    func main<ios15>(tensor<fp32, [?, 224, 224, 3]> input_1) [FlexibleShapeInformation = tuple<tuple<tensor<string, []>, dict<tensor<string, []>, tensor<int32, [?]>>>, tuple<tensor<string, []>, dict<tensor<string, []>, list<tensor<int32, [2]>, ?>>>>((("DefaultShapes", {{"input_1", [1, 224, 224, 3]}}), ("RangeDims", {{"input_1", [[1, 2], [224, 224], [224, 224], [3, 3]]}})))] {
            tensor<int32, [4]> transpose_1_perm_0 = const()[name = tensor<string, []>("transpose_1_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> input_1_to_fp16_dtype_0 = const()[name = tensor<string, []>("input_1_to_fp16_dtype_0"), val = tensor<string, []>("fp16")];
            tensor<string, []> model_Conv1_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_Conv1_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_Conv1_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_Conv1_Conv2Dx_strides_0"), val = tensor<int32, [2]>([2, 2])];
            tensor<int32, [2]> model_Conv1_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_Conv1_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_Conv1_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_Conv1_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_Conv1_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_Conv1_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [32, 3, 3, 3]> model_bn_Conv1_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_bn_Conv1_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [32, 3, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(64)))];
            tensor<fp16, [32]> model_bn_Conv1_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_bn_Conv1_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [32]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1856)))];
            tensor<fp16, [?, 224, 224, 3]> cast_57 = cast(dtype = input_1_to_fp16_dtype_0, x = input_1)[name = tensor<string, []>("cast_57")];
            tensor<fp16, [?, 3, 224, 224]> transpose_164 = transpose(perm = transpose_1_perm_0, x = cast_57)[name = tensor<string, []>("transpose_164")];
            tensor<fp16, [?, 32, 112, 112]> model_bn_Conv1_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_bn_Conv1_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_Conv1_Conv2Dx_dilations_0, groups = model_Conv1_Conv2Dx_groups_0, pad = model_Conv1_Conv2Dx_pad_0, pad_type = model_Conv1_Conv2Dx_pad_type_0, strides = model_Conv1_Conv2Dx_strides_0, weight = model_bn_Conv1_FusedBatchNormV3_nchw_weight_0_to_fp16, x = transpose_164)[name = tensor<string, []>("model_bn_Conv1_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 32, 112, 112]> model_Conv1_relu_Relu6_cast_fp16 = relu6(x = model_bn_Conv1_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_Conv1_relu_Relu6_cast_fp16")];
            tensor<string, []> model_expanded_conv_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_expanded_conv_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_expanded_conv_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_expanded_conv_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_expanded_conv_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_expanded_conv_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_expanded_conv_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_expanded_conv_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(32)];
            tensor<int32, [4]> model_expanded_conv_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_expanded_conv_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [32, 1, 3, 3]> model_expanded_conv_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_expanded_conv_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [32, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1984)))];
            tensor<fp16, [32]> model_expanded_conv_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_expanded_conv_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [32]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(2624)))];
            tensor<fp16, [?, 32, 112, 112]> model_expanded_conv_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_expanded_conv_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_expanded_conv_depthwise_depthwisex_dilations_0, groups = model_expanded_conv_depthwise_depthwisex_groups_0, pad = model_expanded_conv_depthwise_depthwisex_pad_0, pad_type = model_expanded_conv_depthwise_depthwisex_pad_type_0, strides = model_expanded_conv_depthwise_depthwisex_strides_0, weight = model_expanded_conv_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_Conv1_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_expanded_conv_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 32, 112, 112]> model_expanded_conv_depthwise_relu_Relu6_cast_fp16 = relu6(x = model_expanded_conv_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_expanded_conv_depthwise_relu_Relu6_cast_fp16")];
            tensor<string, []> model_expanded_conv_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_expanded_conv_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_expanded_conv_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_expanded_conv_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_expanded_conv_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_expanded_conv_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_expanded_conv_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_expanded_conv_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_expanded_conv_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_expanded_conv_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 32, 1, 1]> model_expanded_conv_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_expanded_conv_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [16, 32, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(2752)))];
            tensor<fp16, [16]> model_expanded_conv_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_expanded_conv_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(3840)))];
            tensor<fp16, [?, 16, 112, 112]> model_expanded_conv_project_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_expanded_conv_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_expanded_conv_project_Conv2Dx_dilations_0, groups = model_expanded_conv_project_Conv2Dx_groups_0, pad = model_expanded_conv_project_Conv2Dx_pad_0, pad_type = model_expanded_conv_project_Conv2Dx_pad_type_0, strides = model_expanded_conv_project_Conv2Dx_strides_0, weight = model_expanded_conv_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_expanded_conv_depthwise_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_expanded_conv_project_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<string, []> model_block_1_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_1_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_1_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_1_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_1_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_1_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_1_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_1_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_1_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_1_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [96, 16, 1, 1]> model_block_1_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_1_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [96, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(3968)))];
            tensor<fp16, [96]> model_block_1_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_1_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(7104)))];
            tensor<fp16, [?, 96, 112, 112]> model_block_1_expand_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_1_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_1_expand_Conv2Dx_dilations_0, groups = model_block_1_expand_Conv2Dx_groups_0, pad = model_block_1_expand_Conv2Dx_pad_0, pad_type = model_block_1_expand_Conv2Dx_pad_type_0, strides = model_block_1_expand_Conv2Dx_strides_0, weight = model_block_1_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_expanded_conv_project_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_1_expand_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 96, 112, 112]> model_block_1_expand_relu_Relu6_cast_fp16 = relu6(x = model_block_1_expand_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_1_expand_relu_Relu6_cast_fp16")];
            tensor<string, []> pad_0_mode_0 = const()[name = tensor<string, []>("pad_0_mode_0"), val = tensor<string, []>("constant")];
            tensor<int32, [8]> pad_4_pad_0 = const()[name = tensor<string, []>("pad_4_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 1, 0, 1])];
            tensor<fp16, []> const_0_to_fp16 = const()[name = tensor<string, []>("const_0_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [?, 96, 113, 113]> pad_4_cast_fp16 = pad(constant_val = const_0_to_fp16, mode = pad_0_mode_0, pad = pad_4_pad_0, x = model_block_1_expand_relu_Relu6_cast_fp16)[name = tensor<string, []>("pad_4_cast_fp16")];
            tensor<string, []> model_block_1_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_block_1_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> model_block_1_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_block_1_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([2, 2])];
            tensor<int32, [2]> model_block_1_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_block_1_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_1_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_block_1_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(96)];
            tensor<int32, [4]> model_block_1_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_block_1_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [96, 1, 3, 3]> model_block_1_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_1_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [96, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(7360)))];
            tensor<fp16, [96]> model_block_1_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_1_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(9152)))];
            tensor<fp16, [?, 96, 56, 56]> model_block_1_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_1_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_1_depthwise_depthwisex_dilations_0, groups = model_block_1_depthwise_depthwisex_groups_0, pad = model_block_1_depthwise_depthwisex_pad_0, pad_type = model_block_1_depthwise_depthwisex_pad_type_0, strides = model_block_1_depthwise_depthwisex_strides_0, weight = model_block_1_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = pad_4_cast_fp16)[name = tensor<string, []>("model_block_1_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 96, 56, 56]> model_block_1_depthwise_relu_Relu6_cast_fp16 = relu6(x = model_block_1_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_1_depthwise_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_1_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_1_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_1_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_1_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_1_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_1_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_1_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_1_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_1_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_1_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [24, 96, 1, 1]> model_block_1_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_1_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [24, 96, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(9408)))];
            tensor<fp16, [24]> model_block_1_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_1_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [24]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(14080)))];
            tensor<fp16, [?, 24, 56, 56]> model_block_1_project_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_1_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_1_project_Conv2Dx_dilations_0, groups = model_block_1_project_Conv2Dx_groups_0, pad = model_block_1_project_Conv2Dx_pad_0, pad_type = model_block_1_project_Conv2Dx_pad_type_0, strides = model_block_1_project_Conv2Dx_strides_0, weight = model_block_1_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_1_depthwise_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_1_project_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<string, []> model_block_2_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_2_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_2_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_2_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_2_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_2_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_2_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_2_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_2_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_2_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [144, 24, 1, 1]> model_block_2_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_2_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [144, 24, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(14208)))];
            tensor<fp16, [144]> model_block_2_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_2_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(21184)))];
            tensor<fp16, [?, 144, 56, 56]> model_block_2_expand_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_2_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_2_expand_Conv2Dx_dilations_0, groups = model_block_2_expand_Conv2Dx_groups_0, pad = model_block_2_expand_Conv2Dx_pad_0, pad_type = model_block_2_expand_Conv2Dx_pad_type_0, strides = model_block_2_expand_Conv2Dx_strides_0, weight = model_block_2_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_1_project_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_2_expand_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 144, 56, 56]> model_block_2_expand_relu_Relu6_cast_fp16 = relu6(x = model_block_2_expand_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_2_expand_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_2_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_block_2_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_2_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_block_2_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_2_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_block_2_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_2_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_block_2_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(144)];
            tensor<int32, [4]> model_block_2_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_block_2_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [144, 1, 3, 3]> model_block_2_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_2_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [144, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(21568)))];
            tensor<fp16, [144]> model_block_2_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_2_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24256)))];
            tensor<fp16, [?, 144, 56, 56]> model_block_2_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_2_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_2_depthwise_depthwisex_dilations_0, groups = model_block_2_depthwise_depthwisex_groups_0, pad = model_block_2_depthwise_depthwisex_pad_0, pad_type = model_block_2_depthwise_depthwisex_pad_type_0, strides = model_block_2_depthwise_depthwisex_strides_0, weight = model_block_2_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_2_expand_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_2_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 144, 56, 56]> model_block_2_depthwise_relu_Relu6_cast_fp16 = relu6(x = model_block_2_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_2_depthwise_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_2_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_2_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_2_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_2_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_2_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_2_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_2_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_2_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_2_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_2_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [24, 144, 1, 1]> model_block_2_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_2_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [24, 144, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24640)))];
            tensor<fp16, [24]> model_block_2_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_2_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [24]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(31616)))];
            tensor<fp16, [?, 24, 56, 56]> model_block_2_project_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_2_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_2_project_Conv2Dx_dilations_0, groups = model_block_2_project_Conv2Dx_groups_0, pad = model_block_2_project_Conv2Dx_pad_0, pad_type = model_block_2_project_Conv2Dx_pad_type_0, strides = model_block_2_project_Conv2Dx_strides_0, weight = model_block_2_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_2_depthwise_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_2_project_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 24, 56, 56]> model_block_2_add_add_cast_fp16 = add(x = model_block_1_project_BN_FusedBatchNormV3_nchw_cast_fp16, y = model_block_2_project_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_2_add_add_cast_fp16")];
            tensor<string, []> model_block_3_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_3_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_3_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_3_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_3_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_3_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_3_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_3_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_3_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_3_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [144, 24, 1, 1]> model_block_3_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_3_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [144, 24, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(31744)))];
            tensor<fp16, [144]> model_block_3_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_3_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(38720)))];
            tensor<fp16, [?, 144, 56, 56]> model_block_3_expand_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_3_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_3_expand_Conv2Dx_dilations_0, groups = model_block_3_expand_Conv2Dx_groups_0, pad = model_block_3_expand_Conv2Dx_pad_0, pad_type = model_block_3_expand_Conv2Dx_pad_type_0, strides = model_block_3_expand_Conv2Dx_strides_0, weight = model_block_3_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_2_add_add_cast_fp16)[name = tensor<string, []>("model_block_3_expand_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 144, 56, 56]> model_block_3_expand_relu_Relu6_cast_fp16 = relu6(x = model_block_3_expand_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_3_expand_relu_Relu6_cast_fp16")];
            tensor<string, []> pad_1_mode_0 = const()[name = tensor<string, []>("pad_1_mode_0"), val = tensor<string, []>("constant")];
            tensor<int32, [8]> pad_5_pad_0 = const()[name = tensor<string, []>("pad_5_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 1, 0, 1])];
            tensor<fp16, []> const_1_to_fp16 = const()[name = tensor<string, []>("const_1_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [?, 144, 57, 57]> pad_5_cast_fp16 = pad(constant_val = const_1_to_fp16, mode = pad_1_mode_0, pad = pad_5_pad_0, x = model_block_3_expand_relu_Relu6_cast_fp16)[name = tensor<string, []>("pad_5_cast_fp16")];
            tensor<string, []> model_block_3_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_block_3_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> model_block_3_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_block_3_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([2, 2])];
            tensor<int32, [2]> model_block_3_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_block_3_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_3_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_block_3_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(144)];
            tensor<int32, [4]> model_block_3_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_block_3_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [144, 1, 3, 3]> model_block_3_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_3_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [144, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(39104)))];
            tensor<fp16, [144]> model_block_3_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_3_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(41792)))];
            tensor<fp16, [?, 144, 28, 28]> model_block_3_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_3_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_3_depthwise_depthwisex_dilations_0, groups = model_block_3_depthwise_depthwisex_groups_0, pad = model_block_3_depthwise_depthwisex_pad_0, pad_type = model_block_3_depthwise_depthwisex_pad_type_0, strides = model_block_3_depthwise_depthwisex_strides_0, weight = model_block_3_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = pad_5_cast_fp16)[name = tensor<string, []>("model_block_3_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 144, 28, 28]> model_block_3_depthwise_relu_Relu6_cast_fp16 = relu6(x = model_block_3_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_3_depthwise_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_3_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_3_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_3_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_3_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_3_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_3_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_3_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_3_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_3_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_3_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [32, 144, 1, 1]> model_block_3_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_3_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [32, 144, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(42176)))];
            tensor<fp16, [32]> model_block_3_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_3_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [32]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(51456)))];
            tensor<fp16, [?, 32, 28, 28]> model_block_3_project_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_3_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_3_project_Conv2Dx_dilations_0, groups = model_block_3_project_Conv2Dx_groups_0, pad = model_block_3_project_Conv2Dx_pad_0, pad_type = model_block_3_project_Conv2Dx_pad_type_0, strides = model_block_3_project_Conv2Dx_strides_0, weight = model_block_3_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_3_depthwise_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_3_project_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<string, []> model_block_4_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_4_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_4_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_4_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_4_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_4_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_4_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_4_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_4_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_4_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [192, 32, 1, 1]> model_block_4_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_4_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [192, 32, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(51584)))];
            tensor<fp16, [192]> model_block_4_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_4_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [192]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(63936)))];
            tensor<fp16, [?, 192, 28, 28]> model_block_4_expand_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_4_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_4_expand_Conv2Dx_dilations_0, groups = model_block_4_expand_Conv2Dx_groups_0, pad = model_block_4_expand_Conv2Dx_pad_0, pad_type = model_block_4_expand_Conv2Dx_pad_type_0, strides = model_block_4_expand_Conv2Dx_strides_0, weight = model_block_4_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_3_project_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_4_expand_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 192, 28, 28]> model_block_4_expand_relu_Relu6_cast_fp16 = relu6(x = model_block_4_expand_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_4_expand_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_4_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_block_4_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_4_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_block_4_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_4_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_block_4_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_4_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_block_4_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(192)];
            tensor<int32, [4]> model_block_4_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_block_4_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [192, 1, 3, 3]> model_block_4_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_4_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [192, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(64384)))];
            tensor<fp16, [192]> model_block_4_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_4_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [192]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(67904)))];
            tensor<fp16, [?, 192, 28, 28]> model_block_4_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_4_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_4_depthwise_depthwisex_dilations_0, groups = model_block_4_depthwise_depthwisex_groups_0, pad = model_block_4_depthwise_depthwisex_pad_0, pad_type = model_block_4_depthwise_depthwisex_pad_type_0, strides = model_block_4_depthwise_depthwisex_strides_0, weight = model_block_4_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_4_expand_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_4_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 192, 28, 28]> model_block_4_depthwise_relu_Relu6_cast_fp16 = relu6(x = model_block_4_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_4_depthwise_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_4_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_4_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_4_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_4_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_4_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_4_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_4_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_4_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_4_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_4_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [32, 192, 1, 1]> model_block_4_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_4_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [32, 192, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(68352)))];
            tensor<fp16, [32]> model_block_4_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_4_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [32]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(80704)))];
            tensor<fp16, [?, 32, 28, 28]> model_block_4_project_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_4_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_4_project_Conv2Dx_dilations_0, groups = model_block_4_project_Conv2Dx_groups_0, pad = model_block_4_project_Conv2Dx_pad_0, pad_type = model_block_4_project_Conv2Dx_pad_type_0, strides = model_block_4_project_Conv2Dx_strides_0, weight = model_block_4_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_4_depthwise_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_4_project_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 32, 28, 28]> model_block_4_add_add_cast_fp16 = add(x = model_block_3_project_BN_FusedBatchNormV3_nchw_cast_fp16, y = model_block_4_project_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_4_add_add_cast_fp16")];
            tensor<string, []> model_block_5_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_5_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_5_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_5_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_5_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_5_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_5_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_5_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_5_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_5_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [192, 32, 1, 1]> model_block_5_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_5_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [192, 32, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(80832)))];
            tensor<fp16, [192]> model_block_5_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_5_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [192]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(93184)))];
            tensor<fp16, [?, 192, 28, 28]> model_block_5_expand_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_5_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_5_expand_Conv2Dx_dilations_0, groups = model_block_5_expand_Conv2Dx_groups_0, pad = model_block_5_expand_Conv2Dx_pad_0, pad_type = model_block_5_expand_Conv2Dx_pad_type_0, strides = model_block_5_expand_Conv2Dx_strides_0, weight = model_block_5_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_4_add_add_cast_fp16)[name = tensor<string, []>("model_block_5_expand_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 192, 28, 28]> model_block_5_expand_relu_Relu6_cast_fp16 = relu6(x = model_block_5_expand_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_5_expand_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_5_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_block_5_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_5_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_block_5_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_5_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_block_5_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_5_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_block_5_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(192)];
            tensor<int32, [4]> model_block_5_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_block_5_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [192, 1, 3, 3]> model_block_5_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_5_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [192, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(93632)))];
            tensor<fp16, [192]> model_block_5_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_5_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [192]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(97152)))];
            tensor<fp16, [?, 192, 28, 28]> model_block_5_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_5_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_5_depthwise_depthwisex_dilations_0, groups = model_block_5_depthwise_depthwisex_groups_0, pad = model_block_5_depthwise_depthwisex_pad_0, pad_type = model_block_5_depthwise_depthwisex_pad_type_0, strides = model_block_5_depthwise_depthwisex_strides_0, weight = model_block_5_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_5_expand_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_5_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 192, 28, 28]> model_block_5_depthwise_relu_Relu6_cast_fp16 = relu6(x = model_block_5_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_5_depthwise_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_5_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_5_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_5_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_5_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_5_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_5_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_5_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_5_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_5_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_5_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [32, 192, 1, 1]> model_block_5_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_5_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [32, 192, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(97600)))];
            tensor<fp16, [32]> model_block_5_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_5_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [32]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(109952)))];
            tensor<fp16, [?, 32, 28, 28]> model_block_5_project_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_5_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_5_project_Conv2Dx_dilations_0, groups = model_block_5_project_Conv2Dx_groups_0, pad = model_block_5_project_Conv2Dx_pad_0, pad_type = model_block_5_project_Conv2Dx_pad_type_0, strides = model_block_5_project_Conv2Dx_strides_0, weight = model_block_5_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_5_depthwise_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_5_project_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 32, 28, 28]> model_block_5_add_add_cast_fp16 = add(x = model_block_4_add_add_cast_fp16, y = model_block_5_project_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_5_add_add_cast_fp16")];
            tensor<string, []> model_block_6_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_6_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_6_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_6_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_6_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_6_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_6_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_6_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_6_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_6_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [192, 32, 1, 1]> model_block_6_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_6_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [192, 32, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(110080)))];
            tensor<fp16, [192]> model_block_6_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_6_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [192]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(122432)))];
            tensor<fp16, [?, 192, 28, 28]> model_block_6_expand_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_6_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_6_expand_Conv2Dx_dilations_0, groups = model_block_6_expand_Conv2Dx_groups_0, pad = model_block_6_expand_Conv2Dx_pad_0, pad_type = model_block_6_expand_Conv2Dx_pad_type_0, strides = model_block_6_expand_Conv2Dx_strides_0, weight = model_block_6_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_5_add_add_cast_fp16)[name = tensor<string, []>("model_block_6_expand_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 192, 28, 28]> model_block_6_expand_relu_Relu6_cast_fp16 = relu6(x = model_block_6_expand_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_6_expand_relu_Relu6_cast_fp16")];
            tensor<string, []> pad_2_mode_0 = const()[name = tensor<string, []>("pad_2_mode_0"), val = tensor<string, []>("constant")];
            tensor<int32, [8]> pad_6_pad_0 = const()[name = tensor<string, []>("pad_6_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 1, 0, 1])];
            tensor<fp16, []> const_2_to_fp16 = const()[name = tensor<string, []>("const_2_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [?, 192, 29, 29]> pad_6_cast_fp16 = pad(constant_val = const_2_to_fp16, mode = pad_2_mode_0, pad = pad_6_pad_0, x = model_block_6_expand_relu_Relu6_cast_fp16)[name = tensor<string, []>("pad_6_cast_fp16")];
            tensor<string, []> model_block_6_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_block_6_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> model_block_6_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_block_6_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([2, 2])];
            tensor<int32, [2]> model_block_6_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_block_6_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_6_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_block_6_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(192)];
            tensor<int32, [4]> model_block_6_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_block_6_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [192, 1, 3, 3]> model_block_6_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_6_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [192, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(122880)))];
            tensor<fp16, [192]> model_block_6_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_6_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [192]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(126400)))];
            tensor<fp16, [?, 192, 14, 14]> model_block_6_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_6_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_6_depthwise_depthwisex_dilations_0, groups = model_block_6_depthwise_depthwisex_groups_0, pad = model_block_6_depthwise_depthwisex_pad_0, pad_type = model_block_6_depthwise_depthwisex_pad_type_0, strides = model_block_6_depthwise_depthwisex_strides_0, weight = model_block_6_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = pad_6_cast_fp16)[name = tensor<string, []>("model_block_6_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 192, 14, 14]> model_block_6_depthwise_relu_Relu6_cast_fp16 = relu6(x = model_block_6_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_6_depthwise_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_6_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_6_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_6_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_6_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_6_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_6_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_6_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_6_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_6_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_6_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [64, 192, 1, 1]> model_block_6_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_6_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [64, 192, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(126848)))];
            tensor<fp16, [64]> model_block_6_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_6_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(151488)))];
            tensor<fp16, [?, 64, 14, 14]> model_block_6_project_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_6_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_6_project_Conv2Dx_dilations_0, groups = model_block_6_project_Conv2Dx_groups_0, pad = model_block_6_project_Conv2Dx_pad_0, pad_type = model_block_6_project_Conv2Dx_pad_type_0, strides = model_block_6_project_Conv2Dx_strides_0, weight = model_block_6_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_6_depthwise_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_6_project_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<string, []> model_block_7_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_7_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_7_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_7_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_7_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_7_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_7_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_7_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_7_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_7_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [384, 64, 1, 1]> model_block_7_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_7_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [384, 64, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(151680)))];
            tensor<fp16, [384]> model_block_7_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_7_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(200896)))];
            tensor<fp16, [?, 384, 14, 14]> model_block_7_expand_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_7_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_7_expand_Conv2Dx_dilations_0, groups = model_block_7_expand_Conv2Dx_groups_0, pad = model_block_7_expand_Conv2Dx_pad_0, pad_type = model_block_7_expand_Conv2Dx_pad_type_0, strides = model_block_7_expand_Conv2Dx_strides_0, weight = model_block_7_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_6_project_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_7_expand_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 384, 14, 14]> model_block_7_expand_relu_Relu6_cast_fp16 = relu6(x = model_block_7_expand_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_7_expand_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_7_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_block_7_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_7_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_block_7_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_7_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_block_7_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_7_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_block_7_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(384)];
            tensor<int32, [4]> model_block_7_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_block_7_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [384, 1, 3, 3]> model_block_7_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_7_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [384, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(201728)))];
            tensor<fp16, [384]> model_block_7_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_7_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208704)))];
            tensor<fp16, [?, 384, 14, 14]> model_block_7_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_7_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_7_depthwise_depthwisex_dilations_0, groups = model_block_7_depthwise_depthwisex_groups_0, pad = model_block_7_depthwise_depthwisex_pad_0, pad_type = model_block_7_depthwise_depthwisex_pad_type_0, strides = model_block_7_depthwise_depthwisex_strides_0, weight = model_block_7_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_7_expand_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_7_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 384, 14, 14]> model_block_7_depthwise_relu_Relu6_cast_fp16 = relu6(x = model_block_7_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_7_depthwise_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_7_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_7_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_7_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_7_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_7_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_7_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_7_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_7_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_7_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_7_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [64, 384, 1, 1]> model_block_7_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_7_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [64, 384, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(209536)))];
            tensor<fp16, [64]> model_block_7_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_7_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(258752)))];
            tensor<fp16, [?, 64, 14, 14]> model_block_7_project_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_7_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_7_project_Conv2Dx_dilations_0, groups = model_block_7_project_Conv2Dx_groups_0, pad = model_block_7_project_Conv2Dx_pad_0, pad_type = model_block_7_project_Conv2Dx_pad_type_0, strides = model_block_7_project_Conv2Dx_strides_0, weight = model_block_7_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_7_depthwise_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_7_project_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 64, 14, 14]> model_block_7_add_add_cast_fp16 = add(x = model_block_6_project_BN_FusedBatchNormV3_nchw_cast_fp16, y = model_block_7_project_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_7_add_add_cast_fp16")];
            tensor<string, []> model_block_8_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_8_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_8_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_8_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_8_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_8_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_8_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_8_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_8_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_8_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [384, 64, 1, 1]> model_block_8_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_8_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [384, 64, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(258944)))];
            tensor<fp16, [384]> model_block_8_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_8_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(308160)))];
            tensor<fp16, [?, 384, 14, 14]> model_block_8_expand_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_8_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_8_expand_Conv2Dx_dilations_0, groups = model_block_8_expand_Conv2Dx_groups_0, pad = model_block_8_expand_Conv2Dx_pad_0, pad_type = model_block_8_expand_Conv2Dx_pad_type_0, strides = model_block_8_expand_Conv2Dx_strides_0, weight = model_block_8_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_7_add_add_cast_fp16)[name = tensor<string, []>("model_block_8_expand_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 384, 14, 14]> model_block_8_expand_relu_Relu6_cast_fp16 = relu6(x = model_block_8_expand_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_8_expand_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_8_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_block_8_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_8_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_block_8_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_8_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_block_8_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_8_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_block_8_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(384)];
            tensor<int32, [4]> model_block_8_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_block_8_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [384, 1, 3, 3]> model_block_8_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_8_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [384, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(308992)))];
            tensor<fp16, [384]> model_block_8_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_8_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(315968)))];
            tensor<fp16, [?, 384, 14, 14]> model_block_8_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_8_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_8_depthwise_depthwisex_dilations_0, groups = model_block_8_depthwise_depthwisex_groups_0, pad = model_block_8_depthwise_depthwisex_pad_0, pad_type = model_block_8_depthwise_depthwisex_pad_type_0, strides = model_block_8_depthwise_depthwisex_strides_0, weight = model_block_8_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_8_expand_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_8_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 384, 14, 14]> model_block_8_depthwise_relu_Relu6_cast_fp16 = relu6(x = model_block_8_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_8_depthwise_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_8_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_8_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_8_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_8_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_8_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_8_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_8_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_8_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_8_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_8_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [64, 384, 1, 1]> model_block_8_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_8_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [64, 384, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(316800)))];
            tensor<fp16, [64]> model_block_8_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_8_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(366016)))];
            tensor<fp16, [?, 64, 14, 14]> model_block_8_project_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_8_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_8_project_Conv2Dx_dilations_0, groups = model_block_8_project_Conv2Dx_groups_0, pad = model_block_8_project_Conv2Dx_pad_0, pad_type = model_block_8_project_Conv2Dx_pad_type_0, strides = model_block_8_project_Conv2Dx_strides_0, weight = model_block_8_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_8_depthwise_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_8_project_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 64, 14, 14]> model_block_8_add_add_cast_fp16 = add(x = model_block_7_add_add_cast_fp16, y = model_block_8_project_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_8_add_add_cast_fp16")];
            tensor<string, []> model_block_9_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_9_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_9_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_9_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_9_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_9_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_9_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_9_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_9_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_9_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [384, 64, 1, 1]> model_block_9_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_9_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [384, 64, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(366208)))];
            tensor<fp16, [384]> model_block_9_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_9_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(415424)))];
            tensor<fp16, [?, 384, 14, 14]> model_block_9_expand_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_9_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_9_expand_Conv2Dx_dilations_0, groups = model_block_9_expand_Conv2Dx_groups_0, pad = model_block_9_expand_Conv2Dx_pad_0, pad_type = model_block_9_expand_Conv2Dx_pad_type_0, strides = model_block_9_expand_Conv2Dx_strides_0, weight = model_block_9_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_8_add_add_cast_fp16)[name = tensor<string, []>("model_block_9_expand_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 384, 14, 14]> model_block_9_expand_relu_Relu6_cast_fp16 = relu6(x = model_block_9_expand_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_9_expand_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_9_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_block_9_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_9_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_block_9_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_9_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_block_9_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_9_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_block_9_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(384)];
            tensor<int32, [4]> model_block_9_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_block_9_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [384, 1, 3, 3]> model_block_9_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_9_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [384, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(416256)))];
            tensor<fp16, [384]> model_block_9_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_9_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(423232)))];
            tensor<fp16, [?, 384, 14, 14]> model_block_9_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_9_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_9_depthwise_depthwisex_dilations_0, groups = model_block_9_depthwise_depthwisex_groups_0, pad = model_block_9_depthwise_depthwisex_pad_0, pad_type = model_block_9_depthwise_depthwisex_pad_type_0, strides = model_block_9_depthwise_depthwisex_strides_0, weight = model_block_9_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_9_expand_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_9_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 384, 14, 14]> model_block_9_depthwise_relu_Relu6_cast_fp16 = relu6(x = model_block_9_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_9_depthwise_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_9_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_9_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_9_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_9_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_9_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_9_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_9_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_9_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_9_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_9_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [64, 384, 1, 1]> model_block_9_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_9_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [64, 384, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(424064)))];
            tensor<fp16, [64]> model_block_9_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_9_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(473280)))];
            tensor<fp16, [?, 64, 14, 14]> model_block_9_project_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_9_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_9_project_Conv2Dx_dilations_0, groups = model_block_9_project_Conv2Dx_groups_0, pad = model_block_9_project_Conv2Dx_pad_0, pad_type = model_block_9_project_Conv2Dx_pad_type_0, strides = model_block_9_project_Conv2Dx_strides_0, weight = model_block_9_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_9_depthwise_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_9_project_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 64, 14, 14]> model_block_9_add_add_cast_fp16 = add(x = model_block_8_add_add_cast_fp16, y = model_block_9_project_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_9_add_add_cast_fp16")];
            tensor<string, []> model_block_10_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_10_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_10_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_10_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_10_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_10_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_10_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_10_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_10_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_10_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [384, 64, 1, 1]> model_block_10_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_10_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [384, 64, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(473472)))];
            tensor<fp16, [384]> model_block_10_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_10_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(522688)))];
            tensor<fp16, [?, 384, 14, 14]> model_block_10_expand_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_10_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_10_expand_Conv2Dx_dilations_0, groups = model_block_10_expand_Conv2Dx_groups_0, pad = model_block_10_expand_Conv2Dx_pad_0, pad_type = model_block_10_expand_Conv2Dx_pad_type_0, strides = model_block_10_expand_Conv2Dx_strides_0, weight = model_block_10_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_9_add_add_cast_fp16)[name = tensor<string, []>("model_block_10_expand_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 384, 14, 14]> model_block_10_expand_relu_Relu6_cast_fp16 = relu6(x = model_block_10_expand_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_10_expand_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_10_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_block_10_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_10_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_block_10_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_10_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_block_10_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_10_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_block_10_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(384)];
            tensor<int32, [4]> model_block_10_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_block_10_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [384, 1, 3, 3]> model_block_10_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_10_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [384, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(523520)))];
            tensor<fp16, [384]> model_block_10_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_10_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(530496)))];
            tensor<fp16, [?, 384, 14, 14]> model_block_10_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_10_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_10_depthwise_depthwisex_dilations_0, groups = model_block_10_depthwise_depthwisex_groups_0, pad = model_block_10_depthwise_depthwisex_pad_0, pad_type = model_block_10_depthwise_depthwisex_pad_type_0, strides = model_block_10_depthwise_depthwisex_strides_0, weight = model_block_10_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_10_expand_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_10_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 384, 14, 14]> model_block_10_depthwise_relu_Relu6_cast_fp16 = relu6(x = model_block_10_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_10_depthwise_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_10_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_10_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_10_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_10_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_10_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_10_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_10_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_10_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_10_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_10_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [96, 384, 1, 1]> model_block_10_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_10_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [96, 384, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(531328)))];
            tensor<fp16, [96]> model_block_10_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_10_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(605120)))];
            tensor<fp16, [?, 96, 14, 14]> model_block_10_project_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_10_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_10_project_Conv2Dx_dilations_0, groups = model_block_10_project_Conv2Dx_groups_0, pad = model_block_10_project_Conv2Dx_pad_0, pad_type = model_block_10_project_Conv2Dx_pad_type_0, strides = model_block_10_project_Conv2Dx_strides_0, weight = model_block_10_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_10_depthwise_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_10_project_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<string, []> model_block_11_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_11_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_11_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_11_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_11_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_11_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_11_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_11_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_11_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_11_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [576, 96, 1, 1]> model_block_11_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_11_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [576, 96, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(605376)))];
            tensor<fp16, [576]> model_block_11_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_11_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(716032)))];
            tensor<fp16, [?, 576, 14, 14]> model_block_11_expand_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_11_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_11_expand_Conv2Dx_dilations_0, groups = model_block_11_expand_Conv2Dx_groups_0, pad = model_block_11_expand_Conv2Dx_pad_0, pad_type = model_block_11_expand_Conv2Dx_pad_type_0, strides = model_block_11_expand_Conv2Dx_strides_0, weight = model_block_11_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_10_project_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_11_expand_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 576, 14, 14]> model_block_11_expand_relu_Relu6_cast_fp16 = relu6(x = model_block_11_expand_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_11_expand_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_11_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_block_11_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_11_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_block_11_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_11_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_block_11_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_11_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_block_11_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(576)];
            tensor<int32, [4]> model_block_11_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_block_11_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [576, 1, 3, 3]> model_block_11_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_11_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [576, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(717248)))];
            tensor<fp16, [576]> model_block_11_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_11_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(727680)))];
            tensor<fp16, [?, 576, 14, 14]> model_block_11_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_11_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_11_depthwise_depthwisex_dilations_0, groups = model_block_11_depthwise_depthwisex_groups_0, pad = model_block_11_depthwise_depthwisex_pad_0, pad_type = model_block_11_depthwise_depthwisex_pad_type_0, strides = model_block_11_depthwise_depthwisex_strides_0, weight = model_block_11_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_11_expand_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_11_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 576, 14, 14]> model_block_11_depthwise_relu_Relu6_cast_fp16 = relu6(x = model_block_11_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_11_depthwise_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_11_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_11_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_11_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_11_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_11_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_11_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_11_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_11_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_11_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_11_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [96, 576, 1, 1]> model_block_11_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_11_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [96, 576, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(728896)))];
            tensor<fp16, [96]> model_block_11_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_11_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(839552)))];
            tensor<fp16, [?, 96, 14, 14]> model_block_11_project_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_11_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_11_project_Conv2Dx_dilations_0, groups = model_block_11_project_Conv2Dx_groups_0, pad = model_block_11_project_Conv2Dx_pad_0, pad_type = model_block_11_project_Conv2Dx_pad_type_0, strides = model_block_11_project_Conv2Dx_strides_0, weight = model_block_11_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_11_depthwise_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_11_project_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 96, 14, 14]> model_block_11_add_add_cast_fp16 = add(x = model_block_10_project_BN_FusedBatchNormV3_nchw_cast_fp16, y = model_block_11_project_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_11_add_add_cast_fp16")];
            tensor<string, []> model_block_12_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_12_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_12_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_12_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_12_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_12_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_12_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_12_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_12_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_12_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [576, 96, 1, 1]> model_block_12_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_12_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [576, 96, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(839808)))];
            tensor<fp16, [576]> model_block_12_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_12_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(950464)))];
            tensor<fp16, [?, 576, 14, 14]> model_block_12_expand_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_12_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_12_expand_Conv2Dx_dilations_0, groups = model_block_12_expand_Conv2Dx_groups_0, pad = model_block_12_expand_Conv2Dx_pad_0, pad_type = model_block_12_expand_Conv2Dx_pad_type_0, strides = model_block_12_expand_Conv2Dx_strides_0, weight = model_block_12_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_11_add_add_cast_fp16)[name = tensor<string, []>("model_block_12_expand_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 576, 14, 14]> model_block_12_expand_relu_Relu6_cast_fp16 = relu6(x = model_block_12_expand_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_12_expand_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_12_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_block_12_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_12_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_block_12_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_12_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_block_12_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_12_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_block_12_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(576)];
            tensor<int32, [4]> model_block_12_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_block_12_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [576, 1, 3, 3]> model_block_12_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_12_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [576, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(951680)))];
            tensor<fp16, [576]> model_block_12_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_12_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(962112)))];
            tensor<fp16, [?, 576, 14, 14]> model_block_12_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_12_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_12_depthwise_depthwisex_dilations_0, groups = model_block_12_depthwise_depthwisex_groups_0, pad = model_block_12_depthwise_depthwisex_pad_0, pad_type = model_block_12_depthwise_depthwisex_pad_type_0, strides = model_block_12_depthwise_depthwisex_strides_0, weight = model_block_12_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_12_expand_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_12_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 576, 14, 14]> model_block_12_depthwise_relu_Relu6_cast_fp16 = relu6(x = model_block_12_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_12_depthwise_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_12_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_12_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_12_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_12_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_12_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_12_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_12_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_12_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_12_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_12_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [96, 576, 1, 1]> model_block_12_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_12_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [96, 576, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(963328)))];
            tensor<fp16, [96]> model_block_12_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_12_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1073984)))];
            tensor<fp16, [?, 96, 14, 14]> model_block_12_project_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_12_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_12_project_Conv2Dx_dilations_0, groups = model_block_12_project_Conv2Dx_groups_0, pad = model_block_12_project_Conv2Dx_pad_0, pad_type = model_block_12_project_Conv2Dx_pad_type_0, strides = model_block_12_project_Conv2Dx_strides_0, weight = model_block_12_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_12_depthwise_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_12_project_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 96, 14, 14]> model_block_12_add_add_cast_fp16 = add(x = model_block_11_add_add_cast_fp16, y = model_block_12_project_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_12_add_add_cast_fp16")];
            tensor<string, []> model_block_13_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_13_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_13_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_13_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_13_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_13_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_13_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_13_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_13_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_13_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [576, 96, 1, 1]> model_block_13_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_13_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [576, 96, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1074240)))];
            tensor<fp16, [576]> model_block_13_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_13_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1184896)))];
            tensor<fp16, [?, 576, 14, 14]> model_block_13_expand_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_13_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_13_expand_Conv2Dx_dilations_0, groups = model_block_13_expand_Conv2Dx_groups_0, pad = model_block_13_expand_Conv2Dx_pad_0, pad_type = model_block_13_expand_Conv2Dx_pad_type_0, strides = model_block_13_expand_Conv2Dx_strides_0, weight = model_block_13_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_12_add_add_cast_fp16)[name = tensor<string, []>("model_block_13_expand_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 576, 14, 14]> model_block_13_expand_relu_Relu6_cast_fp16 = relu6(x = model_block_13_expand_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_13_expand_relu_Relu6_cast_fp16")];
            tensor<string, []> pad_3_mode_0 = const()[name = tensor<string, []>("pad_3_mode_0"), val = tensor<string, []>("constant")];
            tensor<int32, [8]> pad_7_pad_0 = const()[name = tensor<string, []>("pad_7_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 1, 0, 1])];
            tensor<fp16, []> const_3_to_fp16 = const()[name = tensor<string, []>("const_3_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [?, 576, 15, 15]> pad_7_cast_fp16 = pad(constant_val = const_3_to_fp16, mode = pad_3_mode_0, pad = pad_7_pad_0, x = model_block_13_expand_relu_Relu6_cast_fp16)[name = tensor<string, []>("pad_7_cast_fp16")];
            tensor<string, []> model_block_13_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_block_13_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> model_block_13_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_block_13_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([2, 2])];
            tensor<int32, [2]> model_block_13_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_block_13_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_13_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_block_13_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(576)];
            tensor<int32, [4]> model_block_13_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_block_13_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [576, 1, 3, 3]> model_block_13_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_13_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [576, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1186112)))];
            tensor<fp16, [576]> model_block_13_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_13_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1196544)))];
            tensor<fp16, [?, 576, 7, 7]> model_block_13_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_13_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_13_depthwise_depthwisex_dilations_0, groups = model_block_13_depthwise_depthwisex_groups_0, pad = model_block_13_depthwise_depthwisex_pad_0, pad_type = model_block_13_depthwise_depthwisex_pad_type_0, strides = model_block_13_depthwise_depthwisex_strides_0, weight = model_block_13_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = pad_7_cast_fp16)[name = tensor<string, []>("model_block_13_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 576, 7, 7]> model_block_13_depthwise_relu_Relu6_cast_fp16 = relu6(x = model_block_13_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_13_depthwise_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_13_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_13_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_13_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_13_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_13_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_13_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_13_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_13_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_13_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_13_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [160, 576, 1, 1]> model_block_13_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_13_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [160, 576, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1197760)))];
            tensor<fp16, [160]> model_block_13_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_13_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [160]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1382144)))];
            tensor<fp16, [?, 160, 7, 7]> model_block_13_project_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_13_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_13_project_Conv2Dx_dilations_0, groups = model_block_13_project_Conv2Dx_groups_0, pad = model_block_13_project_Conv2Dx_pad_0, pad_type = model_block_13_project_Conv2Dx_pad_type_0, strides = model_block_13_project_Conv2Dx_strides_0, weight = model_block_13_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_13_depthwise_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_13_project_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<string, []> model_block_14_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_14_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_14_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_14_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_14_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_14_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_14_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_14_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_14_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_14_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [960, 160, 1, 1]> model_block_14_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_14_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [960, 160, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1382528)))];
            tensor<fp16, [960]> model_block_14_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_14_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [960]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1689792)))];
            tensor<fp16, [?, 960, 7, 7]> model_block_14_expand_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_14_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_14_expand_Conv2Dx_dilations_0, groups = model_block_14_expand_Conv2Dx_groups_0, pad = model_block_14_expand_Conv2Dx_pad_0, pad_type = model_block_14_expand_Conv2Dx_pad_type_0, strides = model_block_14_expand_Conv2Dx_strides_0, weight = model_block_14_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_13_project_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_14_expand_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 960, 7, 7]> model_block_14_expand_relu_Relu6_cast_fp16 = relu6(x = model_block_14_expand_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_14_expand_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_14_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_block_14_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_14_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_block_14_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_14_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_block_14_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_14_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_block_14_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(960)];
            tensor<int32, [4]> model_block_14_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_block_14_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [960, 1, 3, 3]> model_block_14_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_14_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [960, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1691776)))];
            tensor<fp16, [960]> model_block_14_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_14_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [960]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1709120)))];
            tensor<fp16, [?, 960, 7, 7]> model_block_14_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_14_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_14_depthwise_depthwisex_dilations_0, groups = model_block_14_depthwise_depthwisex_groups_0, pad = model_block_14_depthwise_depthwisex_pad_0, pad_type = model_block_14_depthwise_depthwisex_pad_type_0, strides = model_block_14_depthwise_depthwisex_strides_0, weight = model_block_14_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_14_expand_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_14_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 960, 7, 7]> model_block_14_depthwise_relu_Relu6_cast_fp16 = relu6(x = model_block_14_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_14_depthwise_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_14_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_14_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_14_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_14_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_14_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_14_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_14_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_14_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_14_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_14_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [160, 960, 1, 1]> model_block_14_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_14_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [160, 960, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1711104)))];
            tensor<fp16, [160]> model_block_14_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_14_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [160]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(2018368)))];
            tensor<fp16, [?, 160, 7, 7]> model_block_14_project_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_14_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_14_project_Conv2Dx_dilations_0, groups = model_block_14_project_Conv2Dx_groups_0, pad = model_block_14_project_Conv2Dx_pad_0, pad_type = model_block_14_project_Conv2Dx_pad_type_0, strides = model_block_14_project_Conv2Dx_strides_0, weight = model_block_14_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_14_depthwise_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_14_project_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 160, 7, 7]> model_block_14_add_add_cast_fp16 = add(x = model_block_13_project_BN_FusedBatchNormV3_nchw_cast_fp16, y = model_block_14_project_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_14_add_add_cast_fp16")];
            tensor<string, []> model_block_15_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_15_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_15_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_15_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_15_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_15_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_15_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_15_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_15_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_15_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [960, 160, 1, 1]> model_block_15_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_15_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [960, 160, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(2018752)))];
            tensor<fp16, [960]> model_block_15_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_15_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [960]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(2326016)))];
            tensor<fp16, [?, 960, 7, 7]> model_block_15_expand_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_15_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_15_expand_Conv2Dx_dilations_0, groups = model_block_15_expand_Conv2Dx_groups_0, pad = model_block_15_expand_Conv2Dx_pad_0, pad_type = model_block_15_expand_Conv2Dx_pad_type_0, strides = model_block_15_expand_Conv2Dx_strides_0, weight = model_block_15_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_14_add_add_cast_fp16)[name = tensor<string, []>("model_block_15_expand_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 960, 7, 7]> model_block_15_expand_relu_Relu6_cast_fp16 = relu6(x = model_block_15_expand_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_15_expand_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_15_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_block_15_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_15_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_block_15_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_15_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_block_15_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_15_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_block_15_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(960)];
            tensor<int32, [4]> model_block_15_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_block_15_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [960, 1, 3, 3]> model_block_15_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_15_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [960, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(2328000)))];
            tensor<fp16, [960]> model_block_15_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_15_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [960]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(2345344)))];
            tensor<fp16, [?, 960, 7, 7]> model_block_15_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_15_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_15_depthwise_depthwisex_dilations_0, groups = model_block_15_depthwise_depthwisex_groups_0, pad = model_block_15_depthwise_depthwisex_pad_0, pad_type = model_block_15_depthwise_depthwisex_pad_type_0, strides = model_block_15_depthwise_depthwisex_strides_0, weight = model_block_15_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_15_expand_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_15_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 960, 7, 7]> model_block_15_depthwise_relu_Relu6_cast_fp16 = relu6(x = model_block_15_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_15_depthwise_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_15_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_15_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_15_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_15_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_15_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_15_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_15_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_15_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_15_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_15_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [160, 960, 1, 1]> model_block_15_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_15_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [160, 960, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(2347328)))];
            tensor<fp16, [160]> model_block_15_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_15_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [160]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(2654592)))];
            tensor<fp16, [?, 160, 7, 7]> model_block_15_project_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_15_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_15_project_Conv2Dx_dilations_0, groups = model_block_15_project_Conv2Dx_groups_0, pad = model_block_15_project_Conv2Dx_pad_0, pad_type = model_block_15_project_Conv2Dx_pad_type_0, strides = model_block_15_project_Conv2Dx_strides_0, weight = model_block_15_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_15_depthwise_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_15_project_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 160, 7, 7]> model_block_15_add_add_cast_fp16 = add(x = model_block_14_add_add_cast_fp16, y = model_block_15_project_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_15_add_add_cast_fp16")];
            tensor<string, []> model_block_16_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_16_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_16_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_16_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_16_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_16_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_16_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_16_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_16_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_16_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [960, 160, 1, 1]> model_block_16_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_16_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [960, 160, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(2654976)))];
            tensor<fp16, [960]> model_block_16_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_16_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [960]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(2962240)))];
            tensor<fp16, [?, 960, 7, 7]> model_block_16_expand_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_16_expand_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_16_expand_Conv2Dx_dilations_0, groups = model_block_16_expand_Conv2Dx_groups_0, pad = model_block_16_expand_Conv2Dx_pad_0, pad_type = model_block_16_expand_Conv2Dx_pad_type_0, strides = model_block_16_expand_Conv2Dx_strides_0, weight = model_block_16_expand_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_15_add_add_cast_fp16)[name = tensor<string, []>("model_block_16_expand_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 960, 7, 7]> model_block_16_expand_relu_Relu6_cast_fp16 = relu6(x = model_block_16_expand_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_16_expand_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_16_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_block_16_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_16_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_block_16_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_16_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_block_16_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_16_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_block_16_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(960)];
            tensor<int32, [4]> model_block_16_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_block_16_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [960, 1, 3, 3]> model_block_16_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_16_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [960, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(2964224)))];
            tensor<fp16, [960]> model_block_16_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_16_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [960]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(2981568)))];
            tensor<fp16, [?, 960, 7, 7]> model_block_16_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_16_depthwise_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_16_depthwise_depthwisex_dilations_0, groups = model_block_16_depthwise_depthwisex_groups_0, pad = model_block_16_depthwise_depthwisex_pad_0, pad_type = model_block_16_depthwise_depthwisex_pad_type_0, strides = model_block_16_depthwise_depthwisex_strides_0, weight = model_block_16_depthwise_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_16_expand_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_16_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<fp16, [?, 960, 7, 7]> model_block_16_depthwise_relu_Relu6_cast_fp16 = relu6(x = model_block_16_depthwise_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_block_16_depthwise_relu_Relu6_cast_fp16")];
            tensor<string, []> model_block_16_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_block_16_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_block_16_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_block_16_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_block_16_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_block_16_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_block_16_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_block_16_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_block_16_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_block_16_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [320, 960, 1, 1]> model_block_16_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_block_16_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [320, 960, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(2983552)))];
            tensor<fp16, [320]> model_block_16_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_block_16_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [320]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(3598016)))];
            tensor<fp16, [?, 320, 7, 7]> model_block_16_project_BN_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_block_16_project_BN_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_block_16_project_Conv2Dx_dilations_0, groups = model_block_16_project_Conv2Dx_groups_0, pad = model_block_16_project_Conv2Dx_pad_0, pad_type = model_block_16_project_Conv2Dx_pad_type_0, strides = model_block_16_project_Conv2Dx_strides_0, weight = model_block_16_project_BN_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_16_depthwise_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_block_16_project_BN_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<string, []> model_Conv_1_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_Conv_1_Conv2Dx_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> model_Conv_1_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_Conv_1_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_Conv_1_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_Conv_1_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_Conv_1_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_Conv_1_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_Conv_1_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_Conv_1_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 320, 1, 1]> model_Conv_1_bn_FusedBatchNormV3_nchw_weight_0_to_fp16 = const()[name = tensor<string, []>("model_Conv_1_bn_FusedBatchNormV3_nchw_weight_0_to_fp16"), val = tensor<fp16, [1280, 320, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(3598720)))];
            tensor<fp16, [1280]> model_Conv_1_bn_FusedBatchNormV3_nchw_bias_0_to_fp16 = const()[name = tensor<string, []>("model_Conv_1_bn_FusedBatchNormV3_nchw_bias_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(4417984)))];
            tensor<fp16, [?, 1280, 7, 7]> model_Conv_1_bn_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = model_Conv_1_bn_FusedBatchNormV3_nchw_bias_0_to_fp16, dilations = model_Conv_1_Conv2Dx_dilations_0, groups = model_Conv_1_Conv2Dx_groups_0, pad = model_Conv_1_Conv2Dx_pad_0, pad_type = model_Conv_1_Conv2Dx_pad_type_0, strides = model_Conv_1_Conv2Dx_strides_0, weight = model_Conv_1_bn_FusedBatchNormV3_nchw_weight_0_to_fp16, x = model_block_16_project_BN_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_Conv_1_bn_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_Conv_1_bn_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_Conv_1_bn_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [?, 7, 7, 1280]> transpose_163 = transpose(perm = model_Conv_1_bn_FusedBatchNormV3_to_NHWC_perm_0, x = model_Conv_1_bn_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_163")];
            tensor<fp16, [?, 7, 7, 1280]> model_out_relu_Relu6_cast_fp16 = relu6(x = transpose_163)[name = tensor<string, []>("model_out_relu_Relu6_cast_fp16")];
            tensor<int32, [2]> model_global_average_pooling2d_Mean_axes_0 = const()[name = tensor<string, []>("model_global_average_pooling2d_Mean_axes_0"), val = tensor<int32, [2]>([1, 2])];
            tensor<bool, []> model_global_average_pooling2d_Mean_keep_dims_0 = const()[name = tensor<string, []>("model_global_average_pooling2d_Mean_keep_dims_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [?, 1280]> model_global_average_pooling2d_Mean_cast_fp16 = reduce_mean(axes = model_global_average_pooling2d_Mean_axes_0, keep_dims = model_global_average_pooling2d_Mean_keep_dims_0, x = model_out_relu_Relu6_cast_fp16)[name = tensor<string, []>("model_global_average_pooling2d_Mean_cast_fp16")];
            tensor<fp16, [128, 1280]> transpose_156_cast_fp16_to_fp32_to_fp16 = const()[name = tensor<string, []>("transpose_156_cast_fp16_to_fp32_to_fp16"), val = tensor<fp16, [128, 1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(4420608)))];
            tensor<fp16, [128]> model_dense_BiasAdd_bias_0_to_fp16 = const()[name = tensor<string, []>("model_dense_BiasAdd_bias_0_to_fp16"), val = tensor<fp16, [128]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(4748352)))];
            tensor<fp16, [?, 128]> model_dense_BiasAdd_cast_fp16 = linear(bias = model_dense_BiasAdd_bias_0_to_fp16, weight = transpose_156_cast_fp16_to_fp32_to_fp16, x = model_global_average_pooling2d_Mean_cast_fp16)[name = tensor<string, []>("model_dense_BiasAdd_cast_fp16")];
            tensor<fp16, [?, 128]> model_activation_Relu_cast_fp16 = relu(x = model_dense_BiasAdd_cast_fp16)[name = tensor<string, []>("model_activation_Relu_cast_fp16")];
            tensor<fp16, [64, 128]> transpose_157_cast_fp16_to_fp32_to_fp16 = const()[name = tensor<string, []>("transpose_157_cast_fp16_to_fp32_to_fp16"), val = tensor<fp16, [64, 128]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(4748672)))];
            tensor<fp16, [64]> model_dense_1_BiasAdd_bias_0_to_fp16 = const()[name = tensor<string, []>("model_dense_1_BiasAdd_bias_0_to_fp16"), val = tensor<fp16, [64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(4765120)))];
            tensor<fp16, [?, 64]> model_dense_1_BiasAdd_cast_fp16 = linear(bias = model_dense_1_BiasAdd_bias_0_to_fp16, weight = transpose_157_cast_fp16_to_fp32_to_fp16, x = model_activation_Relu_cast_fp16)[name = tensor<string, []>("model_dense_1_BiasAdd_cast_fp16")];
            tensor<fp16, [?, 64]> model_activation_1_Relu_cast_fp16 = relu(x = model_dense_1_BiasAdd_cast_fp16)[name = tensor<string, []>("model_activation_1_Relu_cast_fp16")];
            tensor<fp16, [7, 64]> transpose_158_cast_fp16_to_fp32_to_fp16 = const()[name = tensor<string, []>("transpose_158_cast_fp16_to_fp32_to_fp16"), val = tensor<fp16, [7, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(4765312)))];
            tensor<fp16, [7]> model_dense_2_BiasAdd_bias_0_to_fp16 = const()[name = tensor<string, []>("model_dense_2_BiasAdd_bias_0_to_fp16"), val = tensor<fp16, [7]>([-0x1.2f4p-6, -0x1.4ecp-2, 0x1.95p-4, -0x1.4p-4, -0x1.dd4p-5, 0x1.f2cp-4, 0x1.46cp-6])];
            tensor<fp16, [?, 7]> model_dense_2_BiasAdd_cast_fp16 = linear(bias = model_dense_2_BiasAdd_bias_0_to_fp16, weight = transpose_158_cast_fp16_to_fp32_to_fp16, x = model_activation_1_Relu_cast_fp16)[name = tensor<string, []>("model_dense_2_BiasAdd_cast_fp16")];
            tensor<int32, []> model_dense_2_Softmax_axis_0 = const()[name = tensor<string, []>("model_dense_2_Softmax_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp16, [?, 7]> model_dense_2_Softmax_cast_fp16 = softmax(axis = model_dense_2_Softmax_axis_0, x = model_dense_2_BiasAdd_cast_fp16)[name = tensor<string, []>("model_dense_2_Softmax_cast_fp16")];
            tensor<string, []> model_dense_2_Softmax_cast_fp16_to_fp32_dtype_0 = const()[name = tensor<string, []>("model_dense_2_Softmax_cast_fp16_to_fp32_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<fp32, [?, 7]> Identity = cast(dtype = model_dense_2_Softmax_cast_fp16_to_fp32_dtype_0, x = model_dense_2_Softmax_cast_fp16)[name = tensor<string, []>("cast_56")];
        } -> (Identity);
}